{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs419_ass2_part3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwH4ZTTPu1lb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as skl\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy as dcopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWkrs2JExd_h"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dirt_5tkvqCy"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WWvIw4mvjdM"
      },
      "source": [
        "# global var\n",
        "phase = \"train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izLJGQ2rvwW9"
      },
      "source": [
        "def normalize(df):\n",
        "    global phase, means, ranges\n",
        "    df = np.array(df, \"float64\")\n",
        "    if phase == \"train\":\n",
        "        means = np.mean(df, axis=0)\n",
        "        ranges = np.ptp(df, axis=0)\n",
        "        zeros = np.where(ranges == 0)\n",
        "        ranges[zeros] = 1\n",
        "        means[zeros] = 0\n",
        "        return (df - means) / ranges\n",
        "    return (df - means) / ranges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjmQH66swGB9"
      },
      "source": [
        "def one_hot(df, col_name, vals):\n",
        "    if len(vals) == 2:\n",
        "        val = vals[0]\n",
        "        df[col_name +\n",
        "            \"_binary\"] = df[col_name].apply(lambda x: 1 if x == val else 0)\n",
        "        return df.drop(col_name, axis=1)\n",
        "    for val in vals:\n",
        "        df[col_name + \"_\" +\n",
        "            val] = df[col_name].apply(lambda x: 1 if x == val else 0)\n",
        "    return df.drop(col_name, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC6USHttwKMU"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "TEdrl9MowX00",
        "outputId": "fd55b934-1084-4809-e963-614c27181541"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x-box</th>\n",
              "      <th>y-box</th>\n",
              "      <th>width</th>\n",
              "      <th>high</th>\n",
              "      <th>onpix</th>\n",
              "      <th>x-bar</th>\n",
              "      <th>y-bar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybr</th>\n",
              "      <th>xy2br</th>\n",
              "      <th>x-ege</th>\n",
              "      <th>xegvy</th>\n",
              "      <th>y-ege</th>\n",
              "      <th>yegvx</th>\n",
              "      <th>letter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>U</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x-box  y-box  width  high  onpix  ...  x-ege  xegvy  y-ege  yegvx  letter\n",
              "0      4      7      5     5      4  ...      3      7      3      7       N\n",
              "1      3      9      4     7      2  ...      3      9      0      8       U\n",
              "2      3      3      4     4      1  ...      3      8      4      8       X\n",
              "3      4      5      5     4      5  ...      5     10      9     10       S\n",
              "4      6      9      8     7      5  ...      3      9      1      8       U\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuUl66nJwZis",
        "outputId": "c43aa195-8db3-4aac-d73c-8ccb27a045ee"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13000, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcRCCyHywUtM",
        "outputId": "db17f84e-9cb5-4f42-a0dc-52ec0aa4829e"
      },
      "source": [
        "#only y onehot encoded\n",
        "one_hot_dict={\"letter\": sorted(df[\"letter\"].unique())}\n",
        "print(one_hot_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'letter': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_n_Lj1ny0MC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f032fc0-9859-40f9-b82c-06090413b727"
      },
      "source": [
        "for col in df.columns:\n",
        "  print(len(df[col].unique()))\n",
        "#we might onehot encode all columns, tbd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhxRk1laxv2W"
      },
      "source": [
        "def preprocess(df):\n",
        "  col_and_type_dict = {\n",
        "      #fill if we encod each columns\n",
        "  }\n",
        "\n",
        "  for col_name in col_and_type_dict.keys():\n",
        "      df = one_hot(df, col_name, col_and_type_dict[col_name])\n",
        "  return normalize(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhpT9s4zwf0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc18394e-92c2-4009-9bea-8b5c5f867451"
      },
      "source": [
        "x_train = df.drop(\"letter\" ,axis=1)\n",
        "y_train = df[[\"letter\"]]\n",
        "x_val = df_val.drop(\"letter\" ,axis=1)\n",
        "y_val = df_val[[\"letter\"]]\n",
        "\n",
        "y_train = one_hot(y_train, \"letter\", one_hot_dict[\"letter\"])\n",
        "y_val = one_hot(y_val, \"letter\", one_hot_dict[\"letter\"])\n",
        "\n",
        "y_train = y_train.to_numpy()\n",
        "y_val = y_val.to_numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weQ_kxNV1Rtj"
      },
      "source": [
        "phase = \"train\"\n",
        "x_train = preprocess(x_train)\n",
        "\n",
        "phase=\"validation\"\n",
        "x_val = preprocess(x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXl0amw_xSRu",
        "outputId": "156c736d-a4f6-4f60-c9e6-cdfde2f86148"
      },
      "source": [
        "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13000, 16) (3500, 16) (13000, 26) (3500, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF3_Km9j2ltT",
        "outputId": "00be0ee1-6163-4ce3-8383-6569a4b16c04"
      },
      "source": [
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "\n",
        "train_data = trainData(torch.FloatTensor(x_train), torch.LongTensor(y_train))\n",
        "\n",
        "\n",
        "class testData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data,y_data):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]  \n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "val_data = testData(torch.FloatTensor(x_val),torch.LongTensor(y_val))\n",
        "\n",
        "print(\"Length of training data is: {}\".format(len(train_data)))\n",
        "print(\"Length of test data is: {}\".format(len(val_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training data is: 13000\n",
            "Length of test data is: 3500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6xXROj4CsO"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC0JYEa54t6M"
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()        \n",
        "        self.layer1 = nn.Linear(x_train.shape[1], 100)\n",
        "        self.layer2 = nn.Linear(100, 50)\n",
        "        self.layer3 = nn.Linear(50, y_train.shape[1])\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.relu1(self.layer1(input))\n",
        "        x = F.dropout(x,0.3)\n",
        "        x = self.relu2(self.layer2(x))\n",
        "        # x = self.bn2(x)\n",
        "        # sampled_noise = torch.autograd.Variable(torch.randn(x.shape).to(device) * 0.01)\n",
        "        # x = x + sampled_noise\n",
        "        x = F.dropout(x,0.2)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "    \n",
        "    def forward_test(self, input):\n",
        "        x = self.relu1(self.layer1(input))\n",
        "        # x = F.dropout(x,0.3)\n",
        "        x = self.relu2(self.layer2(x))\n",
        "        x = self.bn2(x)\n",
        "        # sampled_noise = torch.autograd.Variable(torch.randn(x.shape).to(device) * 0.01)\n",
        "        # x = x + sampled_noise\n",
        "        # x = F.dropout(x,0.2)\n",
        "        x = self.layer3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCmQG7sX6H9P"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MyNet()\n",
        "model.to(device)\n",
        "for layer in model.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "      layer.reset_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJEzgoP05G3I"
      },
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkNb9_3e6Mrr"
      },
      "source": [
        "EPOCHS = 1000\n",
        "LEARNING_RATE = 0.003\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.5)\n",
        "optimizer.zero_grad()\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOivLs4h6iGD",
        "outputId": "417f050d-e4c0-4f71-d1e1-fb807ca9de9b"
      },
      "source": [
        "for e in range(EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for x_train_batch, y_train_batch in train_loader:\n",
        "        \n",
        "        x_train_batch, y_train_batch = x_train_batch.to(device), y_train_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x_train_batch)\n",
        "        y_target = torch.argmax(y_train_batch, axis=1).reshape(-1)\n",
        "        loss = criterion(y_pred, y_target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted = torch.argmax(F.softmax(y_pred.data), axis=1)\n",
        "\n",
        "        correct += (predicted == y_target).sum()\n",
        "        total += float(len(y_train_batch))\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    train_accuracies.append(correct*100/total)\n",
        "    train_losses.append(epoch_loss/len(train_loader))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        for x_val_batch, y_val_batch in val_loader:\n",
        "            \n",
        "            x_val_batch, y_val_batch = x_val_batch.to(device), y_val_batch.to(device)\n",
        "\n",
        "            y_predval = model(x_val_batch)\n",
        "            y_target_val = torch.argmax(y_val_batch, axis=1).reshape(-1)\n",
        "            loss = criterion(y_predval,y_target_val)\n",
        "            \n",
        "            predicted = torch.argmax(F.softmax(y_predval), axis=1)\n",
        "            \n",
        "            correct_val += (predicted==y_target_val).sum()\n",
        "            total_val += float(len(y_val_batch))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_accuracies.append(float(correct_val*100/total_val))\n",
        "    val_losses.append(val_loss/len(val_loader))\n",
        "    if (e+1)%25==0:\n",
        "        print(f'Train Accuracy | Epoch {e+1:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {correct*100/total:.3f}')\n",
        "        print(f'Valid Accuracy | Epoch {e+1:03}: | Loss: {val_loss/len(val_loader):.5f} | Acc: {correct_val*100/total_val:.3f}\\n')\n",
        "        \n",
        "    if val_losses[-1]==min(val_losses):\n",
        "       best_model = dcopy(model)\n",
        "    \n",
        "    patience=100\n",
        "    if e>patience:\n",
        "        if val_losses[-1]>max(val_losses[-patience:-1]):\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy | Epoch 025: | Loss: 0.40759 | Acc: 86.846\n",
            "Valid Accuracy | Epoch 025: | Loss: 0.48734 | Acc: 84.743\n",
            "\n",
            "Train Accuracy | Epoch 050: | Loss: 0.40566 | Acc: 86.554\n",
            "Valid Accuracy | Epoch 050: | Loss: 0.48224 | Acc: 84.486\n",
            "\n",
            "Train Accuracy | Epoch 075: | Loss: 0.40593 | Acc: 86.646\n",
            "Valid Accuracy | Epoch 075: | Loss: 0.47067 | Acc: 85.286\n",
            "\n",
            "Train Accuracy | Epoch 100: | Loss: 0.40296 | Acc: 86.438\n",
            "Valid Accuracy | Epoch 100: | Loss: 0.46180 | Acc: 85.457\n",
            "\n",
            "Train Accuracy | Epoch 125: | Loss: 0.40094 | Acc: 86.962\n",
            "Valid Accuracy | Epoch 125: | Loss: 0.48734 | Acc: 84.429\n",
            "\n",
            "Train Accuracy | Epoch 150: | Loss: 0.40319 | Acc: 86.538\n",
            "Valid Accuracy | Epoch 150: | Loss: 0.47927 | Acc: 85.114\n",
            "\n",
            "Train Accuracy | Epoch 175: | Loss: 0.40545 | Acc: 86.877\n",
            "Valid Accuracy | Epoch 175: | Loss: 0.47188 | Acc: 85.143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "WtT7kNiVB-so",
        "outputId": "168a08c7-4960-439e-8e56-19e71a4b0715"
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb47e409690>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DghJwS0TTA8W"
      },
      "source": [
        "torch.save(model.state_dict(), \"mymodel01.6\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myK6pJfCB8kY"
      },
      "source": [
        "class MyNet01(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet01, self).__init__()        \n",
        "        self.layer1 = nn.Linear(x_train.shape[1], 100)\n",
        "        self.layer2 = nn.Linear(100, 50)\n",
        "        self.layer3 = nn.Linear(50, y_train.shape[1])\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.relu1(self.layer1(input))\n",
        "        x = F.dropout(x,0.3)\n",
        "        x = self.relu2(self.layer2(x))\n",
        "        # x = self.bn2(x)\n",
        "        # sampled_noise = torch.autograd.Variable(torch.randn(x.shape).to(device) * 0.01)\n",
        "        # x = x + sampled_noise\n",
        "        x = F.dropout(x,0.2)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "    \n",
        "    def forward_test(self, input):\n",
        "        x = self.relu1(self.layer1(input))\n",
        "        # x = F.dropout(x,0.3)\n",
        "        x = self.relu2(self.layer2(x))\n",
        "        x = self.bn2(x)\n",
        "        # sampled_noise = torch.autograd.Variable(torch.randn(x.shape).to(device) * 0.01)\n",
        "        # x = x + sampled_noise\n",
        "        # x = F.dropout(x,0.2)\n",
        "        x = self.layer3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_HR8fJ4xzEu",
        "outputId": "91ff18a9-bf90-4b44-f112-159354d6a02e"
      },
      "source": [
        "best_model = MyNet01()\n",
        "best_model.load_state_dict(torch.load(\"mymodel01.6\"))\n",
        "best_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyNet01(\n",
              "  (layer1): Linear(in_features=16, out_features=100, bias=True)\n",
              "  (layer2): Linear(in_features=100, out_features=50, bias=True)\n",
              "  (layer3): Linear(in_features=50, out_features=26, bias=True)\n",
              "  (bn2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (relu2): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vekodLfR8QHC",
        "outputId": "13323658-a790-40ef-fea4-f2c834f1027d"
      },
      "source": [
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "  y_val_pred =best_model.forward_test(torch.FloatTensor(x_val).to(device))\n",
        "  y_val_pred = torch.argmax(F.softmax(y_val_pred), axis=1).cpu()\n",
        "  print(\"roc_auc\", roc_auc_score(y_val_pred, y_val, multi_class=\"ovr\"))\n",
        "  print(\"f1\", f1_score(y_val_pred, np.argmax(y_val, axis=1), average=\"macro\"))\n",
        "  print(\"acc\", (np.array(y_val_pred)==np.argmax(y_val, axis=1)).mean())\n",
        "\n",
        "for i in range(y_val.shape[1]):\n",
        "  acc, total = 0, 0\n",
        "  for j in range(y_val.shape[0]):\n",
        "    if np.argmax(y_val[j]) == i:\n",
        "      total+=1\n",
        "      if y_val_pred[j] == i:\n",
        "        acc+=1\n",
        "  # print(chr(ord('A')+i), acc/total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9651831721822229\n",
            "0.9305337462777759\n",
            "0.9314285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyj6PKehekWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b37267c-151d-4594-f99d-fd353dd9b353"
      },
      "source": [
        "df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "phase=\"testing\"\n",
        "x_test = preprocess(df_test)\n",
        "\n",
        "print(x_test.shape)\n",
        "y_test = np.zeros(x_test.shape[0])\n",
        "test_data = testData(torch.FloatTensor(x_test),torch.FloatTensor(y_val))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  y_test_pred = best_model.forward_test(torch.FloatTensor(x_test).to(device))\n",
        "  y_test_pred = torch.argmax(F.softmax(y_test_pred), axis=1).cpu()\n",
        "\n",
        "y_test_pred = np.array(y_test_pred).reshape(-1, 1)\n",
        "id_col = np.array(list(range(0, len(y_test_pred)))).reshape(-1, 1)\n",
        "\n",
        "np_test = np.concatenate((id_col, y_test_pred), axis=1)\n",
        "df_test = pd.DataFrame(np_test, index=None, columns=[\"id\", \"letters\"])\n",
        "df_test[\"letters\"] = df_test[\"letters\"].apply(lambda x: chr(ord('A')+x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3500, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "SiD7Na_y0fF7",
        "outputId": "c7dd1839-f911-4f54-f905-b4d3c7fa62ca"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>letters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id letters\n",
              "0   0       N\n",
              "1   1       O\n",
              "2   2       O\n",
              "3   3       P\n",
              "4   4       G"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0P-cx6yMEeV"
      },
      "source": [
        "df_test.to_csv(\"test_pred.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJTQJAf6NEP0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}